---
layout: post
title: 趣谈网络协议
date: 2018-12-17
author: Jerry
header-style: text
catalog: true
tags:
 - 读书笔记
 - 计算机网路
---

## 网络分层的真实含义

1. 只要是在网络上跑的包，都是完整的。可以有下层没上层（例如MAC层发现不是发给本机的包后，直接丢弃），但是不可能有上层没下层的情况出现
2. 网络分层的目的在于解决复杂度问题，上层总是依赖于下层，并不是能够独立存在

### 各层之间调用实现方式

下层是知道上层的存在的，可以通过每一层包头里面查看上层用的是什么协议。每一层的处理函数都会在OS启动的时候，注册到内核一个数据结构里面。当数据包到达某一层的时候，通过判断上层是什么协议，然后去找相应的处理函数去调用

## ifconfig&ip addr 发生了什么

### 需要掌握的基础：
- IP地址划分，A/B/C/D/E共5类。
- 无类型域间选路 CIDR
- 如何计算网络号、子网掩码等
- 知道IP中公网地址与私有地址的范围

### 既然MAC地址全世界唯一，为什么不直接用MAC地址通信，还要引入IP

要实现能够两台主机的通信，还需要定位功能，如果直接用MAC地址通信，那么需要建立的映射关系将特别多，考虑到当前如此多的计算机，建立如此大的映射关系不现实，所以引入IP进行定位功能。只有在同一个网络号里面的主机才能用MAC地址进行通信。

### ip addr 详解

`ifconfig`属于`net-tools`工具包，而`ip addr`来自`iproute2`工具包，`iproute2`工具包的出现旨在替换`net-tools`，因为其增加了更多新特性，以及更加统一的命名方法，更加容易使用。但由于历史遗留原因，`net-tools`工具包仍然被广泛应用于现在的系统中。

```
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever

```
以上命令列出了系统中当前存在的所有网卡。

`lo` 表示`loopback`，又称环回接口，往往被分配到`127.0.0.1`这个地址上。这个地址用于**本机通信**，经过**内核处理后直接返回**，不会在任何网络中出现。与此对应的，`scope`中host表示这张网卡仅仅可以供本机相互通信。而global表示这张网卡是可以对外的。

`UP`表示网卡处于启动状态

`BROADCAST`表示这个网卡有广播地址，可以发送广播包

`MULTICAST`表示该网卡可以发送多播包

`LOWER_UP`表示L1是启动的，也即使用网线联网。

`MTU 1500`对应于MAC层允许支持的最大报文长度，加上MAC头部尾部最大共1518字节，如果过长就要进行分片。1500为以太网的默认值。此外，TCP层有一个MSS(Maximum Segment Size，最大分段大小)，它等于MTU减去IP头，再减去TCP头的长度。即在不分片的情况下，TCP里面放的最大内容

`qdisc`为`queueing discipline`，称为排队规则。内核如果需要通过某个网络接口发送数据包，都需要按照这里配置的规则进行发送。其选项最简单的为`pfifo`，表示不对数据包做任何处理，按照先入先出发送。`pfifo_fast`相对复杂，包括三个波段（band），每个波段优先级不同，先发送优先级高的数据包，而在每个波段中使用先进先出。数据包是按照服务类型（Type of Service, TOS）决定到哪一个波段，TOS是IP头部里面的一个字段，代表了当前包的优先级大小。

## DHCP与PXE

### 手动指定IP地址
在Linux中，当某台机器想要向其他机器发送包时，首先会进行判断，要去的这个地址和本机是同一个网段吗，只有是同一个网段的，它才会发送ARP请求，获取MAC地址。

否则，默认逻辑为：如果是一个跨网段调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。也就是本网段的其他主机无法收到该包，这也要求了手动指定的IP地址必须准确无误。

### DHCP
> 动态主机配置协议（Dynamic Host Configuration Protocol, DHCP）

相当于，预先配置好一段共享的IP地址，每一台新接入的机器都通过DHCP协议，来申请IP，用完后，还回去。

***工作方式***

1. DHCP Discover：新来机器使用IP为0.0.0.0发送一个广播包，目的IP为：255.255.255.255，以及使用本机的MAC地址作为源地址，而使用ff:ff:ff:ff:ff:ff作为目的MAC地址。广播包为一个**UDP**包，
2. DHCP Offer：DHCP Server收到该请求后，为其授权分配一个IP地址，并设定了授权的时间、网关、子网掩码等信息，同时保证不会将该IP分配给其他的主机。offer阶段，MAC目的地址与IP目的地址仍然都使用广播地址（因为请求分配IP的主机仍然不知道自己的IP地址）
3. DHCP Request：如果局域网内存在多个DHCP Server，那么这台机器会收到多个IP地址。通常它会选择最先到达的DHCP Offer。然后向网络中发送一个DHCP request**广播**数据包，告诉所有DHCP Server它接受了哪一台服务器提供的IP，并让其他服务器撤销之前的分配，用于分配给其他申请者。由于此时客户机还没有真正确定自己的IP，所以仍然使用0.0.0.0作为源IP，MAC/IP层使用广播地址作为目的地址。
4. 最后，DHCP Server会发送一个广播包ACK告知大家，新加入的成员。

上面可以看到，DHCP分配的IP是有租期的，客户机在租期过去50%的时候，直接向为其分配IP地址的服务器发送DHCP request包要求续期，当收到服务器的ACK响应后，会根据ACK中提供的信息，更新本机的信息。

### PXE

这里不记录了，只要了解下PXE的作用即可，具体再看文章。

> 预启动执行环境（Pre-boot Execution Environment, PXE）主要用于批量的安装操作系统。多用于数据中心中，在云计算中有较大用处

## 从物理层到MAC层

这里我们从网络协议的最底层开始讨论，如何将多台计算机连接起来进行通信。

对于两台计算机来说，最简单的方式通信方式是将这两台电脑直接用**网线连接**起来。

然而对于两台以上的计算机要进行通信的时候，则需要**集线器**将多台机器连接。集线器特点：
1. 工作在物理层
2. 将某个端口收到的字节，转发到**所有**其他端口

当然，如果仅是这样就会出现以下问题：
1. 这个包是发给谁的？总不能一直Hub内所有计算机都能接收到？
2. 如果多台计算机同时发送，会不会发生混乱？有没有谁先发、谁后发的规则？

以上问题就是MAC(媒体访问控制协议，Medium Access Control)层需要解决的问题了。**对于第一个问题**，也就出现了MAC地址，指定了该包是发送给谁的，计算机收到包后，会判断该包是否发送给自己的，如果不是，那么将直接丢弃。MAC层的网络包格式如下：
![](/img/post/computer_network/mac_format.jpg)

**对于第二个问题**，常用的解决策略是多路访问策略，主要有以下三种方式：
1. 信道划分，每个包只能从各自的信道发送与接收。该方法实现简单，但是利用率较差；
2. 轮流协议，即各包轮流发送；
3. 随机接入协议：即每个发送端不管当前局域网内是否拥堵，立即发送自己的包，一旦发现出错后，那么随机休眠一段时间后继续发送。常用的以太网就是使用这种策略进行发送。

回到集线器的问题上来说，由于其会转发包到其他所有端口上去，那么当机器数量较多时候，那么冲突发送的概率也就很大了。此外事实上，对于点对点发送的数据包，转发包到其他所有端口是无意义的，不会被接受，反而浪费带宽。解决这个问题的办法是**网桥，交换机**。由于这些设备在转发时，会对MAC头部检查以确定从哪个端口发送，所以这些设备工作在数据链路层。此外，这些设备都有**自学习算法**，可以自动构建转发表。

### ARP & RARP

**ARP**：当在一个局域网内，我们只知道对方IP，而不知道对方的MAC地址时，就可以通过ARP协议，发送一个**广播包**，获取指定IP机器的MAC地址。当然，机器会缓存ARP得到的结果，避免每次进行广播发送请求。

**RARP**：通过一个MAC地址获取对应的IP地址，这种协议在当前不太常用。之前有无盘工作站，即没有硬盘的机器，无法持久化ip地址到磁盘，但有网卡，这时候就可以使用RARP协议来获取IP地址。

## 交换机与VLAN

当一个局域网中，存在多台交换机时，并且构成环路时，可能出现**广播风暴**的问题，这是因为交换机在自学习的时候，会将包从剩余端口广播发送，当出现环路的时候，也就出现了没有尽头的局面，使得网络带宽被这些广播包占满，造成网络奔溃。

**STP**解决方案：核心思想就是打破图，生成树来解决这种环路。具体细节不再展开，明白其目的即可，为解决广播风暴而生。当然，STP也存在其缺点，因为每次网络拓扑变动，都会引起重新的建树，这一操作相对耗时，会造成一段时间内的网络不可用。

### VLAN

当机器数变多，交换机变多，随之而来的一个问题是，大量广播包在网络上发送，使得性能下降；以及由于广播的原因，可以通过抓包的方式获取即使不是发送给它的包内容，引起安全问题。

VLAN（虚拟局域网）的出现就是解决广播与安全这两个问题而生。使用VLAN，一个交换机上会连属于**多个局域网**的机器。具体做法为：在原来的MAC报文中新增一个TAG：VLAN ID。如果交换机是支持VLAN的，那么交换机在转发时，只会转发到具有相同VLAN ID的口。
![](/img/post/computer_network/vlan_mac_format.jpg)

## ICMP

Internet Control Message Protocol，互联网控制报文协议。工作在**IP层**，常用于错误诊断。
![](/img/post/computer_network/icmp_format.jpg)

主要分为两种:
1. 用于查询报文：如ping命令。在选项数据中，ping报文记录了发送时间，用于计算往返时间
2. 用于差错报文：例如告知终点不可达、源抑制、超时、重定向等。常用的命令有traceroute

### ping

这里需要提一点的是，在很多服务器上都是禁用ping的，因为过多的ping会造成带宽资源的浪费。此时我们可以使用telnet来代替ping。该协议基于TCP/IP。

### traceroute

用于差错报文，通常故意制造一些产生错误的场景来感知链路信息。例如
1. 故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器
2. 故意设置不分片，从而确定路径的MTU

## 网关

这里主要涉及网络层的概念，路由器为这里最重要的设备。

当两台主机互相通信时，首先判断两个IP是否为同一个网段，如果是，那么直接通过ARP协议获取目的主机的MAC地址，然后发送。如果不是同一个网段，那么该主机就会向网关发送该包，由网关进行转发。这里网关往往就是路由器，是一个三层设备，因为其需要解析到IP地址。

对于路由器来说，最重要的一个部分就是路由表了，主要分为静态路由与动态路由。其配置了一条条转发规则，确定发送给目的IP地址的包从哪个端口进行转发出去。

### 网关分类

根据转发过程中IP是否变化，来将网关分为转发网关与NAT网关。

#### 转发网关

在整个两台主机的通信过程中，源IP于目的IP一直不变，只是下层的数据链路层中的MAC地址一直在改变。

#### NAT网关

通常情况下，例如在家中，我们连接WIFI的设备的IP通常为：192.168.0.X等，而这些私有地址同时也可能是其他网络下的地址。仅仅通过这些IP是无法进行通信的，这时就需要NAT网关在转发到另一个网络时，需要将该IP地址映射为一个公有IP地址，在网络上传输的时候，将会用该公有IP地址。到底目的网络后，再根据映射关系进行映射找到目的主机。

这里涉及到的一个重要概念是IP转换，在一个网络中，可能会有多个私有地址转为同一个公有地址，那么当收到消息的时候，如果确定刚才是哪一台主机发送的包呢？答案是：NAT网关会以源IP+源端口的方式记录连接的NAT记录。内部采用哈希匹配算法来建立映射关系。

### 动态路由

我们可以通过指定命令去手动配置路由信息，来做到更细粒度的控制。具体看文章。

动态路由算法主要有两种: 距离矢量算法和链路状态算法。两种算法侧重点不同，各有优缺点，具体看文章。基于两种算法产生了两种协议：BGP协议和OSPF协议。

## UDP

### 特性
1. 无连接的
2. 不保证不丢失
3. 不保证按顺序到达
4. TCP是面向字节流的，而UD是基于**数据报**的，一个个地发，一个个地收
5. 没有拥塞控制
6. 无状态

UDP是面向无连接的。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接特性。因此，建立连接客户端与服务端都需要有一定的资源开销。

### 使用场景
1. 需要资源少，在网络比较好的内网中，或者对于丢包不敏感的应用
2. 不需要一对一沟通，而是可以广播的应用
3. 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩。

关于丢包的场景，虽然UDP不保证，但我们可以通过自己在应用层控制重传

### 实际例子
1. 网页或者APP访问。在移动应用中，由于网络的不稳定，可能频繁出现TCP连接的重连等，使得浪费资源。QUIC协议的出现很大提升了性能。QUIC在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制。
2. 流媒体协议。
3. 实时游戏。
4. 物联网。

总之，在实时领域，UDP通常应用较为广泛。因为TCP的当中间某个包丢失后，会使得后面的所有包都无法被接受，而造成等待，这在实时领域是不给认可的。实时领域为了追求实时性，有时是可以忍受某个包丢失的。

## TCP

### 特点
1. 面向连接的
2. 有序的
3. 可靠的
4. 具有拥塞控制
5. 具有流量控制

还需要掌握的是三次握手，四次挥手的详细状态变化，以及为什么握手需要三次，挥手需要四次。

### 拥塞控制&流量控制

需要掌握的有：
1. 累计确认概念
2. 确认重发机制
3. 如何进行流量控制的，了解双方如何根据各自队列来协调发射与接收
4. 慢开始
5. 拥塞避免算法
6. 快重传

此外，最新的被采用的拥塞避免算法：TCP BBR算法。它主要针对以前算法存在的两个问题被提出:
1. 丢包并不代表网络拥塞，在现有的移动网络中，丢包现象广泛存在，如果一旦发现丢包就认为是网络拥塞了，会造成带宽浪费
2. 实际的包路由过程中，每个中间节点都会具有缓存，当该节点无法处理时，新来的包就会进入缓存，等待被处理。而事实上，缓存的存在会进一步影响延时，最理想的网络状态应该是，发送的速率与网络带宽达到一致。对于TCP拥塞控制来说，当真正发生拥塞时，各中间节点中的缓存都已经被填满了，然而这个时候已经晚了。使得延时更加大。而时延的增大进一步加大了包丢失的概率。

因此BBR主要的工作就是企图找到一个平衡点，就是通过不断的加快发送速度，将带宽填满，但是不填满中间设备的缓存，因为这样会增加延时，在这个平衡点可以很好的达到高带宽和低时延的平衡。

## HTTP

### HTTP2.0
1. HTTP1.1在应用层以**纯文本**的形式进行通信。每次通信都要完整的HTTP头。此外，不考虑HTTP1.1下的pipeline模式，每次请求都是一来一回依次发送，存在实时性与并发性问题。
2. HTTP2.0对头部进行压缩，在链接两端建立一个索引表，对相同的头只发送索引表中的索引，从而节约了空间
3. HTTP2.0将一个TCP连接切分成多个流，每个流都有自己的ID，而且可以双向发送，此外，每个流具有优先级，可以先处理优先级高的流。这就使得多个请求可以并发发送。
4. HTTP2.0将所有的传输信息分割为更小的信息和帧，并对它们采用二进制编码。常见的帧有Header帧，用于传输Header内容，并会开启一个新的流。再就是Data帧，用来传输正文实体。多个Data帧属于同一个流。

![](/img/post/computer_network/http2.jpg)

### QUIC

HTTP2.0虽然增加了并发性，但由于其基于TCO协议，处理包是有严格顺序限制，所以会出现如下情况：

当其中一个数据包遇到问题，TCP连接需要等待这个包完成重传才能继续进行。虽然HTTP2.0通过多个流，使得逻辑上一个TCP连接上并行传输，然而其实还是有顺序的，上图中，stream2的帧还没有收到，stream1中的帧也会因此阻塞。

QUIC特性：
1. 基于UDP，自己维护连接，以一个64位随机数作为ID来标识。
2. 自定义重传机制。类似TCP的序号与应答机制。QUIC每次使用递增的序号进行发送，即使重发也使用递增的序号。并且使用offset来标识两个数据包是否相同
3. 无阻塞的多路复用。同HTTP2.0一样，同一条QUIC连接上可以创建多个stream，来发送多个HTTP请求。但是由于QUIC基于UDP，一个连接上的多个流之间没有依赖，即使stream2丢了一个UDP包，后面跟着stream3的一个UDP包，虽然stream2那个包需要重传，但是stream3无需等待，可以直接进行处理
4. 自定义流量控制。在TCP中，接收端窗口的起始点是下一个要接受并且ACK的包，即便后来的包都到了，放在缓存里，窗口也不能右移，因为TCP的ACK机制是基于序列号的累计应答，一旦ACK了一个序号，说明前面都收到了，所以只要前面没到，后面到了也不能ACK。而QUIC基于offset，每个包到来进入缓存，就可以应答，应答后就不会重发，中间的空档会等待到来或者重发即可。窗口的起始位置为当前收到的最大offset。

## HTTPS

### 对称加密&非对称加密

1. 在对称加密中，加密和解密使用相同的秘钥；而在非对称加密中则不同
2. 对于非对称加密：分为公钥和私钥。公钥加密的信息只有私钥才能解密，**而私钥加密的信息只有公钥才能解密**
3. 对称加密算法相比非对称加密来说，简单很多，因此效率要高于非对称加密。

### HTTPS

在网路上进行信息传输时，对于对称加密来说，难点在于如何确保秘钥只有发送与接收双方知道，避免被中间人劫持造成攻击。

因此HTTPS采用对称加密与非对称加密结合的方式。采用非对称加密的主要作用为用于协商出**一个只有双方才知道**的秘钥，以便之后利用对称加密的性能优势弥补非对称加密的不足。

![](/img/post/computer_network/https.jpg)

这里对称秘钥是根据双方通信建立时约定的随机数生成的。由于之前的通过证书这一非对称加密过程，确保了该对称秘钥只有通信双方才能知道。

### 证书

试想没有证书的情况，建立通信时，服务端将自己的公钥一起发送给客户端，客户端每次发送消息时，首先通过该公钥对信息进行公钥加密后进行传输。由于服务端是唯一持有私钥的一方，所以信息的真实内容只有服务端知晓。但是这样的一个问题在于，由于服务端的公钥是公开的，也就是任何人都可以获取到，那么就会出现这样一种情况，原来的客户端与服务端再进行一段时间的通信后，中间人完全可能替代掉原来的客户端，因为其也持有相同的公钥，然后进行一些攻击。也就是说，单纯使用服务端管理的公钥私钥无法确保在一次通信中，一直是原有的两端再进行通信。

再来介绍下证书，证书可以看做是非对称加密的一个实现。证书通常包含服务端公钥，证书的所有者、发布机构、有效期等。

要实现HTTPS服务，通常服务端需要向权威的证书颁发机构CA申请证书。申请时一般要带上自己的公钥信息。CA机构用**CA的私钥**对该公钥进行加密。

客户端向服务端发起请求时，会发送自身支持的一些列加密套件（如加密算法、HASH算法）。服务端收到后，首先查看是否支持客户端带来的加密套件，如果不支持，就直接断开连接，否则，会选一种加密套件用于之后的传输，然后会以证书的形式返回给客户端。

客户端收到后，首先会进行校验证书的合法性，例如是否过期，是否被吊销，是否是上级CA签发的。CA是分层级的，根CA会授权给子CA，在验证证书的时候，浏览器会调用系统的证书管理器接口对证书路径中的所有证书一级级进行验证，只有路径中的所有证书都是受信任的，整个验证的结果才是受信的。

证书验证通过后，就可以根据CA的公钥，获取服务端的公钥，然后确定对称秘钥了。

## 流媒体协议

先看几个名词：
1. AVI, MPEG, RMVB, MP4, MOV, FLV, MKV等
2. H.261, H.262, H.264等
3. MPEG-1, MPEG-2, MPEG-3等

首先明确一点，视频是有一连串图片构成的，每一帧对应一张图片，当帧率足够高的时候，由于人眼的敏感程度，也就觉得是连续的了。而每一张图片都是由像素组成，每一个像素由RGB组成，每个8位，共24位。这样乘起来后会发现，会特别占空间。因此也就出现了**编码**，进行压缩来节约存储空间。

通用的编码步骤有：帧内预测（去除空间冗余）-> 帧间预测（去除时间冗余） -> 变换 -> 量化（去除视觉冗余，通过降低图像质量提高压缩比） -> 熵编码（去除编码冗余，变长编码）

视频编码的两大流派为：**国际电联下的VCEG**，其对应了上述名词的第二个；**ISO旗下的MPEG**，对应了上述第三个。

编码后视频就编程了二进制，按照一定格式保持在文件里，也就出现了各种各样的视频格式，即名词一。

> 编码后的二进制通过某种网络协进行封装，在网络上传输，也就成了网络直播

![](/img/post/computer_network/live.jpg)


这里需要掌握的是:
1. 时序编码：I帧、P帧、B帧
2. 空间编码：每帧拆分成一系列片，每一片都放在**NALU（网络提取层单元）**里面进行传送
3. 推流用于主播端采集编码后发送到服务端，这里采用的是RTMP协议，该协议基于TCP协议，需要掌握RTMP的握手通信流程。此外正由于其基于TCP，所以不适合做实时流传输，更加合理的是采用基于UDP协议
4. 若观众很多，一台服务器无法支撑，那么需要将流分发到各个离用户最近的边缘服务器，这样用户拉流时就可以就近拉去
5. 拉流通用使用RTMP协议

## P2P

### HTTP vs FTP

首先FTP进行文件传输的时候，需要建立两个连接，一个用于控制，另一个用于数据传输

相比于HTTP，FTP较早出现，主要用于文件传输；而HTTP的出现主要用于网页浏览。而事实上，由于HTTP的不断改进，HTTP1.1 pipeline机制，HTTP2.0等的不断优化，在文件传输速度上要**优于**FTP。

### P2P

如果下载服务器只有一台，那么无疑会对该服务器造成太大压力。这因此也出现了P2P协议：下载资源不会集中地存储在某些设备上，而是分散存储在多台设备上peer，想要下载一个文件的时候，会得到包含该文件的peer，然后与这些peer建立连接进行数据传输。一旦下载了该资源，那么自己也将成为peer中的一员，提供给其他peer进行下载。

种子文件（.torrent文件）包含两部分组成：1)tracker URL；2）文件信息。其中文件信息包括：将文件分段，每段的大小，段的hash值用于校验完整性。

下载时，BT客户度首先解析.torrent文件，得到tracker地址，然后连接tracker服务器。该服务器将包含下载资源的IP地址发给客户度，然后BT客户度和这些IP建立连接进行下载每个段，下载完后与hash进行完整性校验

可见这种方式的P2P特别依赖于tracker，其维护了一个文件的所有地址信息，如果该tracker服务器挂了，那么整个P2P网络也就不可用了。

因此出现了去中心化网络**DHT**（Distributed Hash Table），对应出现了**Kademlia协议**。每个加入这个DHT网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。具体参考文章介绍。

## DNS

DNS层次结构
- 根DNS服务器：返回顶级域DNS服务器的IP地址
- 顶级域DNS服务器：返回权威DNS服务器的IP地址
- 权威DNS服务器：返回相应主机的IP地址

![](/img/post/computer_network/dns.jpg)

### 负载均衡

可以使用DNS解析做负载均衡，分为内部负载均衡与全局负载均衡

#### 内部负载均衡

站在客户度的角度来说，将解析请求发给本地DNS之后，本地DNS全权为它效劳。如果一个域名配置了多个IP地址，那么本地DNS就可以进行负载均衡相关工作

#### 全局负载均衡

更进一步的，我们肯定希望不跨运营商的请求以及就近访问，这样能够带来更好的用户体验。而这可以通过DNS全局负载均衡来实现。

![](/img/post/computer_network/dns_lb.jpg)

第7步，并非像之前那样直接将域名解析成IP然后返回，而是让本地DNS服务器继续请求全局负载均衡器，可以设置多层的全局负载均衡器，比如某一层负责运营商层的选择，某一层负责地域层的解析，返回离用户最近的服务器的IP

### HTTPDNS

传统的DNS解析有如下缺点:
1. 递归解析慢
2. 缓存更新慢，容易造成解析错误
3. 域名转发问题，无法做到最优解析

> HTTPDNS：不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。

为了使用HTTPDNS，往往是手机应用，需要在手机端嵌入支持HTTPDNS的客户端SDK。该SDK中指定了服务器集群的地址

![](/img/post/computer_network/httpdns.jpg)

HTTPDNS通过客户端SDK和服务端，通过HTTP直接调用解析DNS的方式，绕过了传统的DNS。加上其智能调度（动态更新，权重，优先级）与缓存设计（同步更新与异步更新）改进了传统DNS解析的不足。

## CDN

CDN分发系统架构
![](/img/post/computer_network/cdn.jpg)

CDN系统的缓存是一层一层的，如果边缘节点无法提供想要的，则向区域节点请求，如果区域节点无法提供，则向中心节点，最后则向原网站请求。

与DNS的全局负载均衡类似，CDN分发网络也是用类似的思路，为用户选择离其最近的边缘节点进行访问

CDN最擅长缓存静态数据，除此之外还可以缓存流媒体数据。

同时，其也支持动态数据的缓存，分为两种：
1. 边缘计算模式。数据的逻辑计算和存储也相应的存在边缘节点，直接在边缘节点进行计算返回。这需要源站与边缘节点做好数据同步
2. 路径优化模式。数据的计算存储仍然在源站，但是数据下发经过CDN网络，通过对路径优化，做到更快的传输

## 数据中心

![](/img/post/computer_network/rack.jpg)

- 汇聚层将多个机架上的服务器连接起来，形成一个集群，在这个集群中，通过二层网络进行互通。这个区域通常也被称作可用区 available zone
- 当节点数目更多的时候，一个可用区可能放不下，需要将多个可用区连接起来，这里就需要核心交换机实现互联

![](/img/post/computer_network/data_center.jpg)

1. 数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边缘路由器与安全设备
2. 数据中心所有链路都需要高可用。服务器需要绑定多网卡，交换机需要堆叠，三层设备可以通过等价路由，二层设备可以通过Trill协议
3. 随着云计算发展，节点之间的数据交互越来越频繁，而传统的三层架构侧重于外部流量请求内部，因此称为南北流量。因此东西流量逐渐引起重视，代表性的技术是叶脊网络结构

## VPN

当需要将多个数据中心相连接，或者需要办公室和数据中心连接，通常有如下几种方式:
1. 走公网。但是公网不安全，你的隐私可能会被别人偷窥
2. 租用专线。但太贵
3. 使用VPN。这是一种这种方式

> VPN，Virtual Private Network，虚拟专用网络，利用公开网络，建立专用数据传输通道，将远程的分支机构，移动办公人员等连接起来

VPN的实现由多种方式，对于IPsec-VPN来说，其可以保证私密性、完整性、真实性、简单便宜，但是性能较差

MPLS-VPN综合和IP转发模式和ATM的标签转发模式的优势，性能较好，但是需要向运营商购买

### VPN与翻墙

我们常说“我要翻墙，有没有好的VPN推荐一下”。而事实上，使用VPN来翻墙的方式已经过时了，GFW目前能够识别出VPN协议的流量，进而封锁。**VPN事实上是一种加密通信技术，它被设计出来的目的是数据传输安全和网络匿名**

[这篇文章讲述了墙的工作原理、以及VPN,VPS等概念](https://medium.com/@thomas_summon/浅谈vpn-vps-proxy以及shadowsocks之间的联系和区别-b0198f92db1b)

[这篇文章介绍了shadowsocks的工作原理](https://yuerblog.cc/2016/11/23/the-principles-of-shadowsocks/)

## 移动网络

手机上网的流程大致如下：
1. 手机发送无线信号与距离最近的基站相连
2. 基站分为两部分，一部分对外提供无线通信，叫做基站收发信台；另一部分对内连接有线网络，叫做基站控制器。基站收发信台通过无线收到数据后，转发给基站控制器
3. 基站控制器通过有线网络，连接到提供手机业务的运营商数据中心，称为核心网。
4. 核心网还未与互联网连接，这里需要对接入设备进行验证、计费等，所有能成功后，才真正接入互联网

事实上，2G走的还是电话网，直到3G之后才开始走的IP网络。

[5G介绍](https://mp.weixin.qq.com/s?__biz=Mjc1NjM3MjY2MA==&mid=2691354000&idx=2&sn=2e5714f28f3ab8b39acc91f5a125b80d&chksm=a9eb724b9e9cfb5daa96c38ff7f459127f2aaf846e3ad8b533f3360702b197ea77de6748373c&mpshare=1&scene=1&srcid=0110aZWiPUiBe6DA22Wk74oL#rd)

### 关于国外移动上网问题

在国外，如果用的还是国内的手机卡，那么虽然用的是人家外国的基站，但是还是回回到国内给你做校验，收费，实际接入的还是国内的网络，也就无法翻墙了。

## 网络虚拟化

网络虚拟化之后主要关注四个方面问题：共享、隔离、互通、灵活。其中共享和互通主要有三种模式：
1. host-only。使用该模式
2. 桥接。该模式下，物理网卡会与虚拟机网卡都连接到同一个虚拟交换机上，因此，物理网卡和虚拟机属于同一个网络。内部虚拟机互通时走的是二层网络，从而也就会有广播带来的风暴问题
3. NAT。该模式下，虚拟机与物理机分属不同网络。虚拟机想要访问外部网络时，需要将地址NAT转换到外部网络

对于隔离问题来说，同样可以通过VLAN技术，设置两个虚拟机不同的tag，从而使得这两个虚拟机无法通信。具体参考专栏。

## 软件定义网络 SDN

- 用SDN控制整个云里面的网络，就像小区保安从总控室管理整个物业一样，将控制面和数据面进行了分离
- 一种开源的虚拟交换机的实现OpenvSwitch，它能对经过自己的包做任意修改，从而使得云对网络的控制十分灵活
- 将OpenvSwitch引入了云之后，可以使得配置简单而灵活，并且可以解耦物理网络和虚拟网络

## iptables

一个网络请求进一台机器需要做的事情：
![](/img/post/computer_network/package_handle.jpg)

我们需要关注的是其中的五个节点：
1. PREROUTING
2. INPUT
3. FORWARD
4. OUTPUT
5. POSTROUTING

之所以关注这五个节点，是因为Linux内核中有一个叫做`Netfilter`的框架，可以在这些节点上插入`hook`函数，因此就可以在五个部分人为进行干预数据包的处理。一个著名的内核模块实现就是`ip_tables`，对应的用户态客户端命令控制就是`iptables`命令。ip_tables模块主要分为四大类：
- 连接跟踪（conntrack）例如我们私有IP去访问外网时，首先要将该私有IP转为公网IP，但是因为多个私有IP对应着同一个公有IP，所以这时候需要连接跟踪来维护每一条连接
- 数据包过滤（filter）
- 网络地址转换（nat）
- 数据包修改

![](/img/post/computer_network/iptables.jpg)

iptable主要用`表和链`来管理各个规则。我们可以通过iptables命令来在上述五个节点上设置规则，来控制网络包的处理。

## QoS

> QoS: Quality of Service. 通过对网络流量的控制，保证大多数用户的服务质量。

控制一台机器的QoS，分为两个方向，入方向和出方向。但实际我们能控制的只有出方向。虽然我们只能控制出发向，但是我们将入口流量进行重定向到虚拟网卡，然后对虚拟网卡的出口流量进行控制，就能变向实现对入口流量进行控制了。

Linux中主要的策略有：

### 无类别排队规则

#### pfifo_fast

设置三个队列，称为三个band，网络包中有4位TOS，代表着属于哪一个band。这三个band中，band0优先级最高，发送完毕后才轮到band1，最后才是band2
![](/img/post/computer_network/pfifo_fast.jpg)

#### 随机公平队列

![](/img/post/computer_network/failqueue.jpg)

会建立很多的FIFO队列，TCP Session会计算hash值，通过该hash值分配到某个队列。在另一端，网络包会通过轮询策略从各个队列中取出发送

#### 令牌桶规则

所有网络包排成队列，但不是到了队头就能发送，而是需要拿到令牌才能发送。

### 基于类别的队列规则

典型的实现是`分层令牌桶规则HTB`，HTB是一棵树，其严格控制了每条分支上能经过的流量，发送速度。**还一个特性是，不同分支下可以互相借流量，可以使得当前不使用这个分支的流量时候，可以借给另一个分支，从而不浪费带宽，是带宽发挥最大作用**


## 容器网络

容器是一种比虚拟机更加轻量级的隔离方式，主要通过namespace和cgroup技术进行资源的隔离。

容器网络连接到物理网络的方式和虚拟机很像，通过桥接的方式实现一台物理机上的容器进行相互访问，如果要访问外网，最简单的方式还是通过NAT

本文还详细介绍了如何通过这两种方式搭建隔离的网络。

## 容器网络之Flannel
实际用到容器时再看

## 容器网络之Calico
实际用到容器时再看

## RPC

![](/img/post/computer_network/rpc.jpg)
**RPC模型**
当客户端的应用想发起一个远程调用时，它实际是先调用本地的Stub，该Stub负责将调用的接口、方法和参数通过双方约定的协议规范进行编码，然后通过本地的RPCRuntime进行传输，将调用网络包发送到服务器。服务端处理顺序则相反。

可见，一个RPC模型可以分为三层：
- 客户端与服务端。只需专注于业务逻辑处理即可，远程调用就像本地调用一样
- Stub层。处理双方约定好的语法、语义、封装、解封装等
- RPCRuntime。主要处理高性能的传输，以及网络的错误和异常、重试等。

