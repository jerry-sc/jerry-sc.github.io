---
layout: post
title: Linux性能优化
date: 2019-01-21
author: Jerry
header-style: text
catalog: true
tags:
 - Linux
---

# CPU

## 平均负载

我们可以通过`uptime`命令获取系统的平均负载
```shell
> uptime
14:58:54 up 432 days,  1:11,  1 user,  load average: 0.00, 0.00, 0.00
```
这里需要关注的是最后三列，分别表示过去1分钟、5分钟、15分钟的平均负载。

**注意：平均负载不等于CPU使用率**

> 平均负载是指单位时间内，系统处于**可运行状态**和**不可中断状态**的平均**进程数**。

- 可运行状态进程包括**正在使用CPU**的进程以及正在**等待CPU**的就绪进程，对应进程状态R
- 不可中断进程是指正处于内核态关键流程中的进程，并不能被中断。对应进程状态D（Disk Sleep）。

### 不可中断与可中断

OS中分为两种中断，可中断与不可中断，分别对应的进程状态为S与D。
- 处于可中断的进程通常因为**等待某某事件发生（如等待socket连接，等待信号量）**而被挂起。而当这些等待事件发生时，这些进程就会被唤醒。
- 处于不可中断的原因一般如上面所述，进程处于内核态关键流程中，一旦被中断，会引发错误。通常而言，处于该状态的时间较为短暂。比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动代码，并与对应的物理设备进行交互。这时就需要对进程进行保护，以免被中断后，**造成设备陷入不可控状态**。可见不可中断是对系统进程与硬件设备的保护。

按照我的理解，仍旧以read系统调用举例。当CPU执行与设备驱动的内核代码时，即当执行设备控制的时候，这时进程处于D状态。而当控制代码处理完毕后，IO设备开始工作后，即不需要CPU再进行干预时，这时进程处于S，休眠状态，等待DMA数据传送完毕。当数据传输完毕，发送中断后，然后进程再次回到R状态

### 进程状态
[Linux进程状态解析之R、S、D、T、Z、X](https://www.cnblogs.com/YDDMAX/p/4979878.html)
- R
- S
- D
- Z是zombie的缩写，表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（如进程的描述符、PID等）
- I是Idle缩写，表示空闲状态，用在不可中断睡眠的内核线程上，该类进程没有任何负载。
- T或t，表示进程处于暂停或者跟踪状态，当我们用gdb调试一个进程时，进程就会处于该状态
- X表示进程已消亡，也就不会再top或者ps命令中看到

通过`uptime`命令查看系统平均负载时，我们更应该关注的是**整体趋势变化**，而不是某一个值的大小。作者建议**当平均负载高于CPU数量70%的时候**，就应该排除为什么负载高的问题了。

### 平均负载与CPU使用率

再次强调下，两者属于不同范畴，要从各自定义出发去理解。平均负载有时与CPU使用率并不一致。
- CPU密集型进程，使用大量CPU会导致平均负载升高，此时这两者一致
- IO密集型进程，等待IO也会导致平均负载升高，但此时CPU使用率不一定高

也就是说，平均负载高有可能是CPU密集引起，或者由于IO密集引起。

### 性能检测工具

#### sysstat
可以使用`sysstat`包下的`mpstat`与`pidstat`
- `mpstat`是一个常用的多核CPU性能分析工具，用来实时查看每个CPU的性能指标，以及所有CPU的平均指标
- `pidstat`是一个常用的进程性能分析工具，用来实时查看进程的CPU、内存、IO以及上下文切换等性能指标

#### dstat

该工具可以同时查看CPU和IO这两种资源的使用情况，便于对比分析

#### strace

常用于跟踪进程的**系统调用**情况

#### perf

用于查看占用CPU的内核函数

#### pstree

查看进程的父子关系

## CPU上下文切换

上下文切换时由于要保持现场，是需要开销的，所以频繁的上下文切换会导致性能低下。

CPU上下文可以分为三类：

### 进程上下文切换

进程的上下文切换相比其他两类切换更加重，更加占用性能。这是因为进程上下文切换不仅包括虚拟内存、栈、全局变量等用户空间的资源，也包括内核堆栈、寄存器等内核空间的状态。

造成进程切换的原因有：
- 时间片用完
- 进程运行资源不足
- 主动sleep挂起
- 高优先级抢占
- 硬件中断执行中断程序

### 线程上下文切换

由于现代OS线程才是调度的基本单位，而进程是资源拥有的基本单位。线程的切换更加轻量与高效。这是因为在同一进程内的线程切换时，只需保存各线程自己的栈和寄存器，而不需保存虚拟内存那些，因为那些是共享的。

当然不同进程内的线程切换时，由于资源不共享，所以先要进行进程切换。

### 中断上下文切换

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。

但中断上下文切换并不涉及到进程的用户态，所以即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。于是，相比进程上下文切换来说，也更加轻量。

### 如何查看CPU上下文切换情况

同样可以通过`vmstat`来查看系统情况。
- `cs`列context switch，表示每秒上下文切换次数
- `in`列interrupt，表示每秒中断次数
- 其他字段可以man查询

同样可以通过`pidstat`命令加上`-w`参数来查看进程的上下文切换情况。需要注意的是两列：
- `cswch`表示每秒自愿上下文切换次数，如进程无法获取自愿导致的切换
- `nvcswch`表示每秒非自愿上下文切换次数，如时间片用完等强制发生的切换

注意：`-w`参数下只会显示进程的数据，而不会统计线程切换的数据，可以通过`-wt`来包含进线程数据

此外，我们可以通过读取`/proc/interrupts`文件来查看由于**是哪种中断类型**引起上下文切换次数

### 上下文切换多少次合理

根据作者建议，这个数值取决于CPU性能，如果系统上下文切换次数比较稳定，并且一万以内那么都算正常。如果出现数量级增长，就很可能发生问题。我们可以根据上下文切换的类型，来进一步猜测问题所在，如
- 自愿上下文变多了，说明进程都在等待资源，有可能发生了IO等问题
- 非自愿上下文切换变多了，说明进程都在被强制调度，都在抢CPU，说明CPU成了瓶颈
- 中断次数变多了，说明CPU被中断处理程序占用，需要通过查看`/proc/interrupts`来分析具体的中断类型

## CPU使用率

可以通过以下命令获取系统每个CPU不同场景下的使用率情况，以及整体的使用率情况。这里的数字单位是节拍数。为了维护CPU时间，Linux通过事先定义的节拍率来出发时钟中断，使用全局变量`Jiffies`记录**开机以来**的节拍数。每发生一次时钟中断，就+1.
```shell
> cat /proc/stat | grep ^cpu
cpu  6330964998 0 13176596 8568527998 5856564 0 765996 0 0 0
cpu0 1370073649 0 3186942 2354338860 1493387 0 165629 0 0 0
cpu1 2135161003 0 2985880 1590712563 1560081 0 165150 0 0 0
cpu2 1354084485 0 3602822 2370125834 1556406 0 180915 0 0 0
cpu3 1471645860 0 3400951 2253350740 1246689 0 254302 0 0 0
```

这里记录的不同场景有：
- `user`(us)：代表用户态CPU时间。不包括下面nice时间，但包括guest时间
- `nice`(ni)：代表**低优先级用户态**CPU时间，也就是进程的nice值被调整为1-19之间时的CPU时间。而nice取值为-20到19，数值越大，优先级越低
- `system`(sys)：代表内核态CPU时间
- `idle`(id)：代表空闲时间，但不包括IO等待时间
- `iowait`(wa)：代表等待IO的CPU时间。需要注意下该值的计算方法，iowait+idle才真正表示CPU空闲的时间，即iowait统计的是**当CPU空闲以及至少一个IO进程在运行**的时间，iowait为0并不能代表当前没有IO进程，可能只不过当时还有其他进程在占用cpu。此外反之，当iowait很大时，我们也无法光凭这个值就断定系统有很多进程在等待IO，可能只有一个。
- `irq`(hi)：代表处理硬中断的CPU时间
- `softirq`(si)：代表处理软中断CPU时间
- `steal`(st)：虚拟化中的值，当系统运行在虚拟机中，而物理机上还存在其他虚拟机，该值表示被其他虚拟机抢占的CPU时间。通常该值较大表示物理机CPU不足
- `guest`(guest)：代表通过虚拟化运行其他OS的时间，也就是虚拟机的CPU时间

> CPU使用率，就是除了空闲时间外的其他时间占总CPU时间的百分比

由于操作系统会不断更新/proc/stat中数据，所以只需要根据该文件就可以计算出一段时间内的cpu使用率情况。诸如`top`等命令就是这样CPU使用率的，该命令默认统计3秒内的使用率

当我们使用`top`命令查看使用率时，我们可以看到所有CPU的各个场景平均使用情况，以及各个进程的CPU总的使用情况，但无法看到各个进程在各个场景下的CPU使用情况。这是我们仍然可以通过`pidstat`命令来查看更加详细的使用情况，以此来定位进程级的CPU使用情况。

当定位到进程级之后，我们可以继续使用`perf`命令来查看哪个函数或者指令占用CPU时钟最多。

### 系统CPU使用率很高，但为什么找不到CPU的应用?

碰到常规问题无法解释CPU使用率情况时，即当我么通过`top`、`ps aux`等命令无法找到CPU使用率高的应用，但系统CPU使用率却很高的情况时，首先要想到有可能是**短时应用**导致的问题，比如以下两种情况：
- 应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过top等工具也不容易发现
- 应用本身在不停地奔溃重启，而启动过程的资源初始化，很可能占用相当多的CPU

对于这类进程，我们可以用`pstree`或者`execsnoop`命令找到它们的父进程，再从父进程所在的应用入手，排查问题的根源

## 系统出现大量不可中断进程和僵尸进程

### 僵尸进程出现的原因

正常情况下，当一个进程创建了子进程之后，它应该通过系统调用`wait`或者`waitpid`等待子进程结束，然后回收子进程资源（分配给子进程的进程描述符等)；此外，当子进程在结束时，会向它的父进程发送`SIGCHILD`信号，所以父进程也可以注册该信号的处理函数，异步回收资源。

然而如果父进程没有按照上述两个方法做，或者子进程执行太快，父进程还没有来得及处理子进程的状态，子进程就已经退出。这时，子进程就变成了僵尸进程。

通常，僵尸进程持续的时间较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由init进程回收后也会消亡。

然而，如果父进程长时间存在，却不回收子进程资源，那么僵尸进程会一直存在。由于这些僵尸进程占用着进程描述符，长时间不清理，会使得无法创建新的进程。

### 僵尸进程的诊断

僵尸进程的排查相对容易，可以使用`pstree`找出父进程，然后查看父进程代码，检查`wait`或者`pidwait`的调用，或是`SIGCHLD`信号处理函数的注册即可

### 不可中断进程诊断

不可中断进程通常持续的时间很短，若长时间存在，那么出现问题的可能性较大。我们可以通过状态D的进程，使用`strace`找出系统调用函数，进一步分析。有时，当状态为D的进程为僵尸进程时，那么该命令就不工作了，此时，我们可以通过`perf`来找出调用函数。

## 软中断

中断其实是一种异步事件处理机制，可以提高系统的并发处理能力。为了减少对正常进程运行调度的影响，中断处理程序需要尽快完成。**中断关闭性质：当在响应上一次中断时，如果其他部分同时发出了中断信号，此时由于已经在响应其他中断了，那么该中断就会被丢失**

为了解决中断处理程序执行太长以及中断丢失的问题，Linux将中断处理分为两个阶段：
- 上半部：用来快速处理中断，它在中断禁止模式下运行，主要吹跟硬件紧密相关的或者时间敏感的工作，例如执行一些状态更新操作等。通常立即执行，执行非常快，从而解决中断丢失问题。这也就是常说的**硬中断**
- 下半部：延迟处理上半部未完成的工作，通常以**内核线程**方式运行。对应**软中断**

对于软中断，我们可以通过`cat /proc/softirqs`查看各种类型软中断在不同CPU上的累计运行次数。事实上，软中断以内核线程的方式**延迟执行**，每个CPU都对应一个软中断内核线程，由该线程来执行软中断程序。线程名字通常为`ksoftirqd/CPU编号`

此外，软中断不只包括了中断处理程序的下半部，一些内核自定义的事件也属于软中断。

### 诊断方法

当软中断事件过多时，会使得内核线程处理不及时，从而一起CPU使用率升高，进而引发网络收发延迟、调度缓慢等性能问题。例如网络频繁收发小包，会引起网络收发延迟。

当发现软中断占用较大CPU，并且是由`ksoftirqd/CPU编号`引起时，我们首先可以通过一下命令查找由什么类型软中断引起的
```shell
> watch -d cat /proc/softirqs
```
如果发现是由于网络引起时，我们可以继续使用以下命令查看具体的网络收发情况
```shell
> sar -n DEV 1
```
> sar 是一系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据

最后，我们可以通过抓包分析，究竟是发送了什么包，进一步排查具体问题

```shell
> tcpdump -i eth0 -tcp port 80
```

## CPU性能问题分析技巧

[具体参考本文](https://time.geekbang.org/column/article/72685)

CPU性能指标
![cpu_checkpoint](/img/post/linux_performance/cpu-checkpoint.png)

从性能指标出发，查找对应排查工具
![index2tools](/img/post/linux_performance/index2tools.png)

从工具出发，查找该工具能干什么
![tools2index](/img/post/linux_performance/tools2index.png)

不同工具命令之间的关系
![tools_relation](/img/post/linux_performance/tools-relation.png)

## CPU性能优化思路

### 避免过早优化

性能优化是一个复杂的过程，造成性能问题可能是有很多因素共同引起的。只有我们了解清楚了，才应该进行。
- 能否确定优化有效？优化后，能提升多少性能
- 性能问题通常不是独立的，如果有多个性能问题同时发生，应该优化哪一个？
- 提升性能问题的方法有时不止一种，如何选择？

**如何评估性能优化效果**

1. 确定性能的量化指标
2. 测试优化前的性能指标
3. 测试优化后的性能指标

通常建议考虑 **应用程序** 与 **系统资源** 两个维度来确定性能指标。如对于应用程序来说，可以考虑吞吐量、请求延迟等；系统资源角度的，可以考虑CPU使用率等

### CPU优化

应用程序优化建议：
- 编译器优化
- 算法优化
- 异步处理。避免轮询造成的CPU开销
- 多线程代替多进程
- 善用缓存

系统优化建议：
- CPU绑定。把进程绑定到一个或者多个CPU上，提高缓存命中率，减少跨CPU调度带来的上下文切换问题
- CPU独占
- 优先级调整。适当降低非核心应用的优先级
- 为进程栓塞制资源限制。使用Linux cgroups设置进程的CPU上限，防止由于某个应用自身问题，而耗尽系统资源
- 中断负载均衡。将中断处理过程自动负载均衡到多个CPU上

# Linux内存

虚拟空间分为内核空间与用户空间，以32位系统举例，如下图所示。
![virtual_memory](/img/post/linux_performance/virtual-memory.png)

用户空间从低地址到高地址分别是五种不同内存段
1. 只读段，包括**代码**与**常量**
2. 数据段，包括**全局变量**等
3. 堆，包括动态分配的内存，从低地址开始向上增长
4. 文件映射段，包括动态库，共享内存等，从高地址向下减小
5. 栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是8M

## 动态内存分配

`malloc`是C标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 `brk()`和 `mmap()`
- `brk`。对于小块内存（小于128K），C标准库使用brk来分配，也即移动堆顶指针位置来分配。这些内存释放后不会立刻归还系统，而是被缓存起来，这样就可以重复使用。缓存的一个好处在于，可以不会频繁的发生缺页中断，提供内存访问效率。不足之处在于频繁的分配与释放会造成内存碎片。所以Linux提供了其他补偿机制，例如stab来管理小内存
- `mmap`。对于大块内存（大于128K），直接使用mmap在 **文件映射段** 中找出一块空闲内存分配。使用该方式分配的内存在使用完毕后会立即归还系统。所以如果频繁发生，会带来大量的缺页中断。

当内存资源紧张时，系统会通过一系列来回收内存：
- 回收缓存，例如使用LRU算法，回收最近最少使用的内存页面
- 使用SWAP
- 杀死进程，报OOM(Out of Memory)

Linux为每个进程设置了oom_score，如果该值越高，代表该进程越有可能被杀掉。当然，我们可以手动设置进行人为干预。

## 内存查看工具

#### free

显示的两行分别表示物理内存Mem和交换分区Swap的使用情况。

- total。总内存大小
- used。已使用内存大小，包括共享内存
- free。未使用内存
- shared。共享内存，指所有进程共同使用的内存、加载的动态链接库以及程序代码段
- buff/cache。缓存和缓冲区大小
- available。新进程可用内存大小。不仅包含未使用内存，还包括可回收的缓存，所以一般比未使用内存大

#### top/ps

- VIRT。进程虚拟内存大小。 **注意：进程申请内存后，并不会立即分配，只有首次访问时，才会发生中断进行分配**。该值值申请的内存大小，即使没有真正分配也会计算在内。
- RES。常驻内存大小，也就是进程实际使用的物理内存大小，但不包括swap和共享内存
- SHR。共享内存大小
- %MEM。进程使用的物理内存占系统总内存百分比。

# 文件系统

> Linux中一切皆文件

文件系统为每个文件都分配两个数据结构， `索引节点` 和 `目录项`。用来记录文件的元信息和目录结构。

- 索引节点inode。用来记录文件的元数据，比如inode编号、文件大小、访问权限、修改日期、数据位置等。**索引节点和文件一一对应，是每个文件的唯一标识**，此外，索引节点和文件内容一样，都会被持久化存储到磁盘中。 **所以索引节点同样占用磁盘空间**
- 目录项dentry。用来记录文件的名字、索引节点指针以及其他目录项的关联关系（例如父子关系）。多个关联的目录项，就成了文件系统的目录结构。 **目录项和索引节点的关系是多对一，即一个文件可以有多个别名**。不过，不同于索引节点， **目录项是内和维护的一个内存数据结构，不会持久化到磁盘，只会存在于缓存中**

**软链接与硬链接**

- 硬链接为文件创建的别名，会对应不同的目录项，但是这些目录项本质上海市链接到同一个文件。所以它们的索引节点相同
- 软链接则真正创建了一个文件，只不过这个文件比较特殊，其内容指向了要被链接的文件的目录项。所以软链接创建的文件与原始文件有着不同的inode

![dentry&inode](/img/post/linux_performance/dentry-inode.png)

- 这里，磁盘读写以扇区管理，然而扇区只有512B大小，如果每次读写这么小的单位，会使得效率较低。所以文件系统以块为单位管理数据，常见逻辑块大小为4KB，即连续8个扇区组成
- 如前所述，目录项本身就在于内存中，而索引节点开始存在于磁盘中。为了协调慢速磁盘与快速CPU的性能差异，索引节点在系统运行后， **也会被缓存到内存中，加速文件访问**
- 磁盘在执行文件系统格式化时，会被分成三个区域，超级块（存储整个文件系统状态）；索引节点区（用来存储索引节点）；数据块（存储文件数据）


##
